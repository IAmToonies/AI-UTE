{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a31096b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\n",
      "  Downloading SpeechRecognition-3.9.0-py2.py3-none-any.whl (32.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m702.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /home/toonies/anaconda3/envs/Chat-bot/lib/python3.7/site-packages (from SpeechRecognition) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/toonies/anaconda3/envs/Chat-bot/lib/python3.7/site-packages (from requests>=2.26.0->SpeechRecognition) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/toonies/anaconda3/envs/Chat-bot/lib/python3.7/site-packages (from requests>=2.26.0->SpeechRecognition) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/toonies/anaconda3/envs/Chat-bot/lib/python3.7/site-packages (from requests>=2.26.0->SpeechRecognition) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/toonies/anaconda3/envs/Chat-bot/lib/python3.7/site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
      "Installing collected packages: SpeechRecognition\n",
      "Successfully installed SpeechRecognition-3.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2aae0553",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bd2034",
   "metadata": {},
   "source": [
    "dic=('afrikaans', 'af', 'albanian', 'sq', 'amharic', 'am',  'arabic', 'ar', 'armenian', 'hy', 'azerbaijani', 'az', 'basque', 'eu', 'belarusian', 'be', 'bengali', 'bn', 'bosnian',     'bs', 'bulgarian', 'bg', 'catalan', 'ca',  'cebuano', 'ceb', 'chichewa', 'ny', 'chinese(simplified)',  'zh-cn', 'chinese (traditional)', 'zh-tw',  'corsican', 'co', 'croatian', 'hr', 'czech', 'cs', 'danish',     'da', 'dutch', 'nl', 'english', 'en', 'esperanto',  'eo', 'estonian', 'et', 'filipino', 'tl', 'finnish', 'fi',  'french', 'fr', 'frisian', 'fy', 'galician', 'gl’,   'georgian', 'ka', 'german', 'de', 'greek', 'el', 'gujarati',      'gu', 'haitian creole', 'ht', 'hausa', 'ha',   'hawaiian', 'haw', 'hebrew', 'he', 'hindi', 'hi', 'hmong',  'hmn', 'hungarian', 'hu', 'icelandic', 'is', 'igbo’, 'ig', 'indonesian', 'id', 'irish', 'ga', 'italian', 'it', 'japanese', 'ja', 'javanese', 'jw', 'kannada', 'kn',  'kazakh', 'kk', 'khmer', 'km', 'korean', 'ko', 'kurdish (kurmanji)’, 'ku', 'kyrgyz', 'ky', 'lao', 'lo', 'latin', 'la', 'latvian', 'lv', 'lithuanian', 'lt', 'luxembourgish’,  'lb', 'macedonian', 'mk','malagasy’,  'mg', 'malay', 'ms', 'malayalam', 'ml', 'maltese', 'mt', 'maori’,  'mi', 'marathi', 'mr', 'mongolian', 'mn’, 'myanmar (burmese)', 'my', 'nepali', 'ne', 'norwegian', 'no’, 'odia', 'or', 'pashto', 'ps', 'persian’, 'fa', 'polish', 'pl', 'portuguese', 'pt', 'punjabi', 'pa’, 'romanian', 'ro', 'russian', 'ru', 'samoan’, 'sm', 'scots gaelic', 'gd', 'serbian', 'sr', 'sesotho', 'st', 'shona', 'sn', 'sindhi', 'sd', 'sinhala’, 'si', 'slovak', 'sk', 'slovenian', 'sl', 'somali', 'so', 'spanish', 'es', 'sundanese', 'su', 'swahili', 'sw', 'swedish', 'sv', 'tajik', 'tg', 'tamil’, 'ta', 'telugu', 'te', 'thai', 'th', 'turkish', 'tr’, 'ukrainian', 'uk', 'urdu', 'ur', 'uyghur', 'ug', 'uzbek', 'uz', 'vietnamese', 'vi', 'welsh', 'cy', 'xhosa', 'xh’, 'yiddish', 'yi', 'yoruba', 'yo', 'zulu', 'zu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1040e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.87634128,\n",
      "                           'transcript': '철수 씨가 어디에 있어요 아마 학교에서 공부 수업이 끝나지 '\n",
      "                                         '않았어요 수업이 있어요 그 수업을 왜 선택했어요 예쁜 여자가 많기 '\n",
      "                                         '때문에 선택했어요 씨가 어디에 있어요 아마 학교에서 공부해요 '\n",
      "                                         '학교에 갔어요 수업이니 끝나지 않았어요 아니요 밤에도 수업이 '\n",
      "                                         '있어요 철수 씨가 그 수업을 왜 선택했어요 그 수업에 예쁜 여자가 '\n",
      "                                         '많기 때문에 선택했어요'},\n",
      "                       {   'transcript': '철수 씨가 어디에 있어요 아마 학교에서 공부 수업이 끝나지 '\n",
      "                                         '않았어요 수업이 있어요 수업을 왜 선택했어요 예쁜 여자가 많기 '\n",
      "                                         '때문에 선택했어요 씨가 어디에 있어요 아마 학교에서 공부해요 '\n",
      "                                         '학교에 갔어요 수업이니 끝나지 않았어요 아니요 밤에도 수업이 '\n",
      "                                         '있어요 철수 씨가 그 수업을 왜 선택했어요 그 수업에 예쁜 여자가 '\n",
      "                                         '많기 때문에 선택했어요'},\n",
      "                       {   'transcript': '철수가 어디에 있어요 아마 학교에서 공부 수업이 끝나지 않았어요 '\n",
      "                                         '수업이 있어요 그 수업을 왜 선택했어요 예쁜 여자가 많기 때문에 '\n",
      "                                         '선택했어요 씨가 어디에 있어요 아마 학교에서 공부해요 학교에 '\n",
      "                                         '갔어요 수업이니 끝나지 않았어요 아니요 밤에도 수업이 있어요 철수 '\n",
      "                                         '씨가 그 수업을 왜 선택했어요 그 수업에 예쁜 여자가 많기 때문에 '\n",
      "                                         '선택했어요'},\n",
      "                       {   'transcript': '철수가 어디에 있어요 아마 학교에서 공부 수업이 끝나지 않았어요 '\n",
      "                                         '수업이 있어요 수업을 왜 선택했어요 예쁜 여자가 많기 때문에 '\n",
      "                                         '선택했어요 씨가 어디에 있어요 아마 학교에서 공부해요 학교에 '\n",
      "                                         '갔어요 수업이니 끝나지 않았어요 아니요 밤에도 수업이 있어요 철수 '\n",
      "                                         '씨가 그 수업을 왜 선택했어요 그 수업에 예쁜 여자가 많기 때문에 '\n",
      "                                         '선택했어요'},\n",
      "                       {   'transcript': '철수 씨가 어디에 있어요 아마 학교에서 공부 수업이 끝나지 '\n",
      "                                         '않았어요 밤에도 수업이 있어요 수업을 왜 선택했어요 예쁜 여자가 '\n",
      "                                         '많기 때문에 선택했어요 씨가 어디에 있어요 아마 학교에서 공부해요 '\n",
      "                                         '학교에 갔어요 수업이 이미 끝나지 않았어요 아니요 밤에도 수업이 '\n",
      "                                         '있어요 철수 씨가 그 수업을 왜 선택했어요 그 수업에 예쁜 여자가 '\n",
      "                                         '많기 때문에 선택했어요'}],\n",
      "    'final': True}\n",
      "철수 씨가 어디에 있어요 아마 학교에서 공부 수업이 끝나지 않았어요 수업이 있어요 그 수업을 왜 선택했어요 예쁜 여자가 많기 때문에 선택했어요 씨가 어디에 있어요 아마 학교에서 공부해요 학교에 갔어요 수업이니 끝나지 않았어요 아니요 밤에도 수업이 있어요 철수 씨가 그 수업을 왜 선택했어요 그 수업에 예쁜 여자가 많기 때문에 선택했어요\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "r = sr.Recognizer()\n",
    "test =sr.AudioFile('./data/music/chap20.wav')\n",
    "with test as source:\n",
    "    data = r.record(source)\n",
    "    text = r.recognize_google(data, language = 'ko') # en, ko, km, lao, ja, vn\n",
    "    print(text.format(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e536660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.92154491,\n",
      "                           'transcript': 'Cháu lên ba cháu đi mẫu giáo cô '\n",
      "                                         'thương cháu không khóc nhè không '\n",
      "                                         'khóc nhè để mẹ trồng cây trái vào '\n",
      "                                         'nhà máy ông bà vui cấy cày lalala'},\n",
      "                       {   'transcript': 'Cháu lên ba cháu đi mẫu giáo cô '\n",
      "                                         'thương cháu không khóc nhè không '\n",
      "                                         'khóc nhè để mẹ trồng cây trái vào '\n",
      "                                         'nhà máy ông bà vui cấy cày lalala '\n",
      "                                         'lalala'},\n",
      "                       {   'transcript': 'Cháu lên ba cháu đi mẫu giáo Cháu '\n",
      "                                         'không khóc nhè không khóc nhè để mẹ '\n",
      "                                         'trồng cây trái vào nhà máy ông bà '\n",
      "                                         'vui cấy cày lalala'},\n",
      "                       {   'transcript': 'Cháu lên ba cháu đi mẫu giáo Cháu '\n",
      "                                         'không khóc nhè không khóc nhè để mẹ '\n",
      "                                         'trồng cây trái vào nhà máy ông bà '\n",
      "                                         'vui cấy cày lalala lalala'},\n",
      "                       {   'transcript': 'Cháu lên ba cháu đi mẫu giáo cô '\n",
      "                                         'thương cháu vì cháu không khóc nhè '\n",
      "                                         'không khóc nhè để mẹ trồng cây trái '\n",
      "                                         'vào nhà máy ông bà vui cấy cày '\n",
      "                                         'lalala'}],\n",
      "    'final': True}\n",
      "Cháu lên ba cháu đi mẫu giáo cô thương cháu không khóc nhè không khóc nhè để mẹ trồng cây trái vào nhà máy ông bà vui cấy cày lalala\n",
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.77111918,\n",
      "                           'transcript': 'trồng cây và lalala Cháu Lên Ba mẹ '\n",
      "                                         'trồng cây trái vào nhà máy'},\n",
      "                       {   'transcript': 'lalala lalala Cháu Lên Ba mẹ trồng '\n",
      "                                         'cây trái vào nhà máy'},\n",
      "                       {   'transcript': 'trồng cây và lalala Cháu Lên Ba mẹ '\n",
      "                                         'trồng cây trái vào nhà Mai'},\n",
      "                       {   'transcript': 'lalala lalala Cháu Lên Ba mẹ trồng '\n",
      "                                         'cây trái vào nhà Mai'},\n",
      "                       {   'transcript': 'lalala Cháu Lên Ba mẹ trồng cây trái '\n",
      "                                         'vào nhà máy'}],\n",
      "    'final': True}\n",
      "trồng cây và lalala Cháu Lên Ba mẹ trồng cây trái vào nhà máy\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "r = sr.Recognizer()\n",
    "test =sr.AudioFile('./data/music/chaulenba.wav')\n",
    "\n",
    "# Dùng offset 18, duration 9 để cắt đoạn từ 18s đến (18+9 = 27s)\n",
    "#0s-----18s---------------(18+9)s------|\n",
    "#|------|-------------------|----------|\n",
    "\n",
    "with test as source:\n",
    "    data = r.record(source, offset=18,duration = 20)\n",
    "    text = r.recognize_google(data, language = 'vi') # en, ko, km, lao, ja, vn\n",
    "    print(text)\n",
    "\n",
    "with test as source:\n",
    "    data1 = r.record(source, offset=18+9,duration = 28)\n",
    "    text = r.recognize_google(data1, language = 'vi') # en, ko, km, lao, ja, vn\n",
    "    print(text.format(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "222a7e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trồng cây và lalala Cháu Lên Ba mẹ trồng cây trái vào nhà máy'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fff8383f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gTTS\n",
      "  Downloading gTTS-2.3.2-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in /home/toonies/anaconda3/envs/Chat-bot/lib/python3.7/site-packages (from gTTS) (8.1.3)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /home/toonies/anaconda3/envs/Chat-bot/lib/python3.7/site-packages (from gTTS) (2.28.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/toonies/anaconda3/envs/Chat-bot/lib/python3.7/site-packages (from click<8.2,>=7.1->gTTS) (4.11.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/toonies/anaconda3/envs/Chat-bot/lib/python3.7/site-packages (from requests<3,>=2.27->gTTS) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/toonies/anaconda3/envs/Chat-bot/lib/python3.7/site-packages (from requests<3,>=2.27->gTTS) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/toonies/anaconda3/envs/Chat-bot/lib/python3.7/site-packages (from requests<3,>=2.27->gTTS) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/toonies/anaconda3/envs/Chat-bot/lib/python3.7/site-packages (from requests<3,>=2.27->gTTS) (2022.6.15)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/toonies/anaconda3/envs/Chat-bot/lib/python3.7/site-packages (from importlib-metadata->click<8.2,>=7.1->gTTS) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/toonies/anaconda3/envs/Chat-bot/lib/python3.7/site-packages (from importlib-metadata->click<8.2,>=7.1->gTTS) (3.11.0)\n",
      "Installing collected packages: gTTS\n",
      "Successfully installed gTTS-2.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e38903a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting playsound\n",
      "  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: playsound\n",
      "  Building wheel for playsound (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7020 sha256=9ca769f11a4e4d3d7961d505a343208a725d2a6160ec3b86061ea697dca209fa\n",
      "  Stored in directory: /home/toonies/.cache/pip/wheels/2a/a3/27/c0e30fc4dd7b159143551de6281bc8dbf298f7245ac385b87b\n",
      "Successfully built playsound\n",
      "Installing collected packages: playsound\n",
      "Successfully installed playsound-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0ac8e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import os\n",
    "from playsound import playsound\n",
    "\n",
    "A = \"Lượm là một bài thơ 4 chữ được viết bởi nhà thơ Tố Hữu vào năm 1949\"\n",
    "speak = gTTS(text = A, lang = 'vi', slow = False)\n",
    "speak.save('week13.mp3')\n",
    "\n",
    "# playsound('week13.mp3')\n",
    "# os.remove('week13.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe4040f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googletrans==3.1.0a0\n",
      "  Downloading googletrans-3.1.0a0.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting httpx==0.13.3\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m225.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m202.3 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting idna==2.*\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m75.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m70.1 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting chardet==3.*\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m271.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /home/toonies/anaconda3/envs/Chat-bot/lib/python3.7/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.2.0)\n",
      "Collecting hstspreload\n",
      "  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m284.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi in /home/toonies/anaconda3/envs/Chat-bot/lib/python3.7/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2022.6.15)\n",
      "Collecting httpcore==0.9.*\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[?25hCollecting rfc3986<2,>=1.3\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting h11<0.10,>=0.8\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h2==3.*\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m467.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m479.0 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting hyperframe<6,>=5.2.0\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting hpack<4,>=3.0\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for googletrans: filename=googletrans-3.1.0a0-py3-none-any.whl size=16353 sha256=04a62468061c3f07ffa2daf42b892c278d19b7fa66e2714b726e42461fe7fe9f\n",
      "  Stored in directory: /home/toonies/.cache/pip/wheels/61/f7/ef/4d5c03c448eb8583bc063caca7e8802d8801af40c65e9b8022\n",
      "Successfully built googletrans\n",
      "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "Successfully installed chardet-3.0.4 googletrans-3.1.0a0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2023.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install googletrans==3.1.0a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f9b1d85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planting trees and lalala Grandson Up Parents plant fruit trees in the factory\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "translation = translator.translate(text, dest = 'en')\n",
    "print(translation.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f650003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m807.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/toonies/anaconda3/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/toonies/anaconda3/lib/python3.9/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/toonies/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m788.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /home/toonies/anaconda3/lib/python3.9/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/toonies/anaconda3/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m606.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/toonies/anaconda3/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in /home/toonies/anaconda3/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: fsspec in /home/toonies/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2022.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/toonies/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/toonies/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/toonies/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/toonies/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/toonies/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/toonies/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f9c636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840d8daea69d446a9ac89c691e5ce6be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 18:30:48.093211: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-05 18:30:48.189646: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb526525cf44313bc595cd7038d1524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee00779a3244468caa85384bb55e93ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83fe318058d451297c7fd2c10679b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94de8656acf41ef9a1a77f9a93b6c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toonies/anaconda3/lib/python3.9/site-packages/transformers/generation/tf_utils.py:745: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Please, talk about VietNam, talk about this new piece of media, about how much better your world looks, how much richer is your country.\\n\\nWhat is wrong with this story and any other news at the moment? I'm the editor of The New York Times.\\n\\nOn a recent day in North Korea, I met a young man trying to read a book about how Kim Jong Un might rule the most populous nation in the world. When I asked him why he had become\"},\n",
       " {'generated_text': \"Please, talk about VietNam or something. I'll be sure to let you know.\\n\\nThanks,\"},\n",
       " {'generated_text': 'Please, talk about VietNam! We want to have a conversation about this issue. We want to address Vietnam and we need to talk about the fact that they have invaded the island.\"\\n\\nThe president is asking the South Vietnamese government if there is any doubt as to her intentions. \"They say she\\'s an American. My answer... they say no, there are enough problems. We have got to make sure all the people are in the right, not here and there. But, I'},\n",
       " {'generated_text': 'Please, talk about VietNam. I had no idea you liked this piece. It\\'s not much of a spoiler.\\n\\nVietnam and Laos\\n\\n\"Dangkok-Kung\" by Y.L. T. Zong\\n\\nKangkok. A language for Vietnamese.\\n\\nA language for Vietnamese. \"Ching-yung\" by J.R. Chiang\\n\\nNing-yung is another name given to some very cool'},\n",
       " {'generated_text': \"Please, talk about VietNam. What the hell is this?\\n\\nWe haven't had a chance to review any of these things (of interest to you all) so here's what you can expect:\\n\\n1 year of play starts\\n\\nThe only players who are getting active to play this year are those who started as rookies (they're the only players who can join the team, not those whose careers began outside of training camps). Of the three rookies who started in 2015 but\"}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "generator = pipeline('text-generation', model ='gpt2')\n",
    "set_seed(42)\n",
    "generator('Please, talk about VietNam', max_length = 100, num_return_sequences = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43af1b8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TextGenerationPipeline' object has no attribute 'named_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3740/2642769691.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'generated_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'TextGenerationPipeline' object has no attribute 'named_steps'"
     ]
    }
   ],
   "source": [
    "generator.named_steps[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13a6773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
